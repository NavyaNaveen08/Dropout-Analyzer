{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b39323-45da-4362-a46e-9ebd6143ba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_keras_datasets():\n",
    "    (x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = keras.datasets.mnist.load_data()\n",
    "    (x_train_fashion, y_train_fashion), (x_test_fashion, y_test_fashion) = keras.datasets.fashion_mnist.load_data()\n",
    "    (x_train_cifar10, y_train_cifar10), (x_test_cifar10, y_test_cifar10) = keras.datasets.cifar10.load_data()\n",
    "    (x_train_cifar100, y_train_cifar100), (x_test_cifar100, y_test_cifar100) = keras.datasets.cifar100.load_data()\n",
    "    (x_train_imdb, y_train_imdb), (x_test_imdb, y_test_imdb) = keras.datasets.imdb.load_data(num_words=10000)\n",
    "    (x_train_reuters, y_train_reuters), (x_test_reuters, y_test_reuters) = keras.datasets.reuters.load_data(num_words=10000)\n",
    "    \n",
    "    return {\n",
    "        \"mnist\": (x_train_mnist, y_train_mnist, x_test_mnist, y_test_mnist),\n",
    "        \"fashion_mnist\": (x_train_fashion, y_train_fashion, x_test_fashion, y_test_fashion),\n",
    "        \"cifar10\": (x_train_cifar10, y_train_cifar10, x_test_cifar10, y_test_cifar10),\n",
    "        \"cifar100\": (x_train_cifar100, y_train_cifar100, x_test_cifar100, y_test_cifar100),\n",
    "        \"imdb\": (x_train_imdb, y_train_imdb, x_test_imdb, y_test_imdb),\n",
    "        \"reuters\": (x_train_reuters, y_train_reuters, x_test_reuters, y_test_reuters)\n",
    "    }\n",
    "\n",
    "datasets = load_keras_datasets()\n",
    "\n",
    "def preprocess_images(x_train, x_test):\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    return x_train, x_test\n",
    "\n",
    "for key in [\"mnist\", \"fashion_mnist\", \"cifar10\", \"cifar100\"]:\n",
    "    datasets[key] = preprocess_images(datasets[key][0], datasets[key][2]) + (datasets[key][1], datasets[key][3])\n",
    "\n",
    "def build_model(input_shape, output_shape, dropout_rate, task_type, activation):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(64, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    if task_type == 'classification':\n",
    "        final_activation = 'softmax' if output_shape > 2 else 'sigmoid'\n",
    "        loss = 'sparse_categorical_crossentropy' if output_shape > 2 else 'binary_crossentropy'\n",
    "        model.add(layers.Dense(output_shape, activation=final_activation))\n",
    "        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    else:\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softmax']\n",
    "dropout_rate = 0.3  \n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    best_score = float('-inf')\n",
    "    best_activation = None\n",
    "    \n",
    "    for activation in activations:\n",
    "        print(f'Training {name} with activation: {activation}')\n",
    "        model = build_model(X_train.shape[1:], len(np.unique(y_train)), dropout_rate, 'classification', activation)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        \n",
    "        test_loss, test_metric = model.evaluate(X_test, y_test, verbose=0)\n",
    "        results[f'{name}_{activation}'] = test_metric\n",
    "        \n",
    "        if test_metric > best_score:\n",
    "            best_score = test_metric\n",
    "            best_activation = activation\n",
    "    \n",
    "    print(f'Best activation for {name}: {best_activation}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for name in datasets.keys():\n",
    "    plt.plot(activations, [results[f'{name}_{act}'] for act in activations], marker='o', label=name)\n",
    "plt.title('Activation Function Effect on Model Performance')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Performance Metric')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "filename = '2216052_Navya_Naveen.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6986baba-c6ed-405d-958a-9d20fab32034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.datasets import load_digits, load_iris, load_wine, load_breast_cancer, make_classification\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "toy_datasets = {\n",
    "    \"digits\": load_digits(return_X_y=True),\n",
    "    \"iris\": load_iris(return_X_y=True),\n",
    "    \"wine\": load_wine(return_X_y=True),\n",
    "    \"breast_cancer\": load_breast_cancer(return_X_y=True)\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "for name, (X, y) in toy_datasets.items():\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    datasets[name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "def build_model(input_shape, output_shape, dropout_rate, activation):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(64, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    final_activation = 'softmax' if output_shape > 2 else 'sigmoid'\n",
    "    loss = 'sparse_categorical_crossentropy' if output_shape > 2 else 'binary_crossentropy'\n",
    "    model.add(layers.Dense(output_shape, activation=final_activation))\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softmax']\n",
    "dropout_rate = 0.3 \n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    best_score = float('-inf')\n",
    "    best_activation = None\n",
    "    \n",
    "    for activation in activations:\n",
    "        print(f'Training {name} with activation: {activation}')\n",
    "        model = build_model((X_train.shape[1],), len(np.unique(y_train)), dropout_rate, activation)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        \n",
    "        test_loss, test_metric = model.evaluate(X_test, y_test, verbose=0)\n",
    "        results[f'{name}_{activation}'] = test_metric\n",
    "        \n",
    "        if test_metric > best_score:\n",
    "            best_score = test_metric\n",
    "            best_activation = activation\n",
    "    \n",
    "    print(f'Best activation for {name}: {best_activation}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for name in datasets.keys():\n",
    "    plt.plot(activations, [results[f'{name}_{act}'] for act in activations], marker='o', label=name)\n",
    "plt.title('Activation Function Effect on Model Performance')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Performance Metric')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "filename = 'toy_datasets_results.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9b133-1d93-41cb-a9ef-ea82e8f55c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "real_world_datasets = {\n",
    "    \"credit_g\": fetch_openml(name=\"credit-g\", as_frame=True),\n",
    "    \"phoneme\": fetch_openml(name=\"phoneme\", as_frame=True),\n",
    "    \"diabetes\": fetch_openml(name=\"diabetes\", as_frame=True),\n",
    "    \"blood_transfusion\": fetch_openml(name=\"blood-transfusion-service-center\", as_frame=True)\n",
    "}\n",
    "\n",
    "datasets = {}\n",
    "for name, dataset in real_world_datasets.items():\n",
    "    X, y = dataset.data, dataset.target\n",
    "    X = X.select_dtypes(include=[np.number]).fillna(0) \n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    datasets[name] = (X_train, X_test, y_train, y_test)\n",
    "\n",
    "def build_model(input_shape, output_shape, dropout_rate, task_type, activation):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(256, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(128, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(64, activation=activation))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    if task_type == 'classification':\n",
    "        final_activation = 'softmax' if output_shape > 2 else 'sigmoid'\n",
    "        loss = 'sparse_categorical_crossentropy' if output_shape > 2 else 'binary_crossentropy'\n",
    "        model.add(layers.Dense(output_shape, activation=final_activation))\n",
    "        model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    else:\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "activations = ['relu', 'tanh', 'sigmoid', 'softmax']\n",
    "dropout_rate = 0.3  \n",
    "results = {}\n",
    "\n",
    "for name, (X_train, X_test, y_train, y_test) in datasets.items():\n",
    "    best_score = float('-inf')\n",
    "    best_activation = None\n",
    "    \n",
    "    for activation in activations:\n",
    "        print(f'Training {name} with activation: {activation}')\n",
    "        model = build_model((X_train.shape[1],), len(np.unique(y_train)), dropout_rate, 'classification', activation)\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
    "        \n",
    "        test_loss, test_metric = model.evaluate(X_test, y_test, verbose=0)\n",
    "        results[f'{name}_{activation}'] = test_metric\n",
    "        \n",
    "        if test_metric > best_score:\n",
    "            best_score = test_metric\n",
    "            best_activation = activation\n",
    "    \n",
    "    print(f'Best activation for {name}: {best_activation}')\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for name in datasets.keys():\n",
    "    plt.plot(activations, [results[f'{name}_{act}'] for act in activations], marker='o', label=name)\n",
    "plt.title('Activation Function Effect on Model Performance')\n",
    "plt.xlabel('Activation Function')\n",
    "plt.ylabel('Performance Metric')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "filename = '2216052_Navya_Naveen.pkl'\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
